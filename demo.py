from torchvision import models, transforms
from gradcam import GradCAM
import utils as util
#from utils import load_image, save_img_with_heatmap, check_path_exist, apply_transforms, save_heatmap
import time
import json
#from utils import get_transform
import cv2
import matplotlib.pyplot as plt
import numpy as np
import os
from PIL import Image
import torch
import torchvision.transforms as transforms


# Load target iamge
script_dir = os.path.dirname(os.path.abspath(__file__))
#image_path = os.path.join(script_dir, 'data_examples/dog-park.jpg')

image_dir = 'D:/anita/Research/competitions/imagenet-object-localization-challenge/ILSVRC/ILSVRC/Data/CLS-LOC/'
image1_path = os.path.join(image_dir, 'val/ILSVRC2012_val_00049991.JPEG')
image2_path = os.path.join(image_dir, 'train/n01484850/n01484850_375.JPEG')
image3_path = os.path.join(image_dir, 'val/ILSVRC2012_val_00049991.JPEG')



# Define a transform to convert PIL images to tensors
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize image to 224x224
    transforms.ToTensor()           # Convert image to tensor
])

# Load images
image_paths = [image1_path, image2_path, image3_path]
images = [transform(Image.open(path)) for path in image_paths]

# Stack images into a single tensor
batch_tensor = torch.stack(images, dim=0)


#image_file = 'data_examples/dog-park.jpg' # More examples exist in the examples folder
#img = util.load_image(image_path)
#plt.imshow(img)
#plt.axis('off')
#plt.show()


def saliency_visualisation(img, saliency):
    fig, ax = plt.subplots(1,2)
    img_heatmap = util.save_img_with_heatmap(img, saliency, None, style='zhou', normalise=True)
    # plt.imshow((img_heatmap[:, :, ::-1]).astype(np.uint8))
    ax[0].imshow((img_heatmap[:, :, ::-1]).astype(np.uint8))
    heatmap = util.save_heatmap(saliency, None, normalise=True)
    ax[1].imshow((heatmap[:, :, ::-1]).astype(np.uint8))
    plt.axis('off')

# Model and base visualisation method initialisation
model = 'resnet50'
target_layer = 'layer4'
model = models.__dict__[model](pretrained=True).eval()
model = model.cuda()

gc = GradCAM(model, target_layer)
transform = util.get_transform(resize_size=224, center_crop_size=None)
x = transform(img).unsqueeze(0)
start = time.time()
saliency, _ = gc(x, None)
print('Total time: {:.2f} second'.format((time.time()-start)))
saliency = cv2.resize(np.squeeze(saliency), img.size)
print('Saliency generated by Grad-CAM')
saliency_visualisation(img, saliency)

#add bouding box around ROI
# Convert the saliency map to binary
threshold = 0.5  # adjust this value to suit your case
_, binary_saliency = cv2.threshold(saliency, threshold, 255, cv2.THRESH_BINARY)

# Convert binary_saliency to 8-bit image
binary_saliency = np.uint8(binary_saliency)
img_np = np.array(img)
# Find contours in the binary image
contours, _ = cv2.findContours(binary_saliency, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# For each contour, find the bounding rectangle and draw it on the original image
for contour in contours:
    x, y, w, h = cv2.boundingRect(contour)
    cv2.rectangle(img_np, (x, y), (x+w, y+h), (0, 255, 0), 2)

# Display the image with bounding boxes
plt.imshow(img_np)
plt.axis('off')
plt.show()


